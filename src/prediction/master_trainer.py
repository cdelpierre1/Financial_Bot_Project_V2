"""
Master Model Trainer ‚Äî Syst√®me de mod√®le ma√Ætre combinant daily/hourly/5min

Architecture:
- 3 sous-mod√®les sp√©cialis√©s par timeframe (daily, hourly, 5min)
- 1 mod√®le ma√Ætre qui apprend √† combiner leurs pr√©dictions
- Auto-entra√Ænement continu et adaptation dynamique aux conditions de march√©
"""
from __future__ import annotations

import os
import json
import pandas as pd
import numpy as np
from datetime import datetime, timezone, timedelta
from typing import Dict, Any, List, Optional, Tuple

from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error

from prediction.trainer import Trainer
from prediction.model_store import ModelStore
from prediction.feature_builder import FeatureBuilder
from storage.parquet_writer import ParquetWriter


class MasterModelTrainer:
    """
    Entra√Æneur de mod√®les ma√Ætres pour syst√®me hybride multi-timeframe.
    
    Combine les pr√©dictions de sous-mod√®les sp√©cialis√©s (daily, hourly, 5min)
    en un mod√®le ma√Ætre plus robuste et pr√©cis.
    """
    
    def __init__(self):
        self.trainer = Trainer()
        self.store = ModelStore()
        self.fb = FeatureBuilder()
        self.pw = ParquetWriter()
    
    def train_sub_models(self, df: pd.DataFrame, coin_id: str, horizon_minutes: int) -> Dict[str, Any]:
        """Entra√Æne les 3 sous-mod√®les (daily, hourly, 5min) pour un horizon donn√©."""
        results = {"sub_models": {}, "errors": []}
        
        timeframes = ['daily', 'hourly', '5min']
        
        for timeframe in timeframes:
            try:
                print(f"    üß† Entra√Ænement sous-mod√®le {timeframe}...")
                
                # Entra√Æner le sous-mod√®le
                result = self.trainer.train(df, coin_id, horizon_minutes)
                
                print(f"      üîç Debug result: {result}")
                
                if result.get("status") == "OK" and (result.get("mae") is not None or result.get("mae_score") is not None):
                    # R√©cup√©rer MAE (peut √™tre "mae" ou "mae_score")
                    mae = result.get("mae") or result.get("mae_score")
                    print(f"      ‚úÖ Sous-mod√®le {timeframe}: MAE={mae:.4f}")
                    
                    # Sauvegarder avec nom sp√©cifique au timeframe
                    model_path = result.get("path") or result.get("model_path")
                    timeframe_path = model_path.replace(f"__{horizon_minutes}m.pkl", f"__{timeframe}_{horizon_minutes}m.pkl")
                    
                    # Copier le mod√®le vers le path sp√©cifique au timeframe
                    import shutil
                    shutil.copy2(model_path, timeframe_path)
                    
                    results["sub_models"][timeframe] = {
                        "path": timeframe_path,
                        "mae": mae,
                        "status": "OK"
                    }
                else:
                    status = result.get("status", "UNKNOWN")
                    print(f"      ‚ùå √âchec sous-mod√®le {timeframe} - Status: {status}")
                    if "rows" in result:
                        print(f"      üìä Donn√©es disponibles: {result['rows']} lignes")
                    results["errors"].append(f"√âchec sous-mod√®le {timeframe}: {status}")
                    
            except Exception as e:
                print(f"      ‚ùå ERREUR sous-mod√®le {timeframe}: {e}")
                import traceback
                print(f"      üìç D√©tails: {traceback.format_exc()}")
                results["errors"].append(f"Erreur sous-mod√®le {timeframe}: {e}")
        
        return results
    
    def train_master_model(self, coin_id: str, test_data: Dict[str, pd.DataFrame], 
                          horizon_minutes: int = 10) -> Dict[str, Any]:
        """Entra√Æne le mod√®le ma√Ætre qui combine les pr√©dictions des sous-mod√®les."""
        try:
            print(f"    üéØ Entra√Ænement mod√®le ma√Ætre...")
            
            # Collecter toutes les pr√©dictions des sous-mod√®les
            sub_predictions = {}
            all_features = {}
            all_targets = {}
            
            # Phase 1: Charger tous les sous-mod√®les et g√©n√©rer leurs pr√©dictions
            for timeframe, df in test_data.items():
                if df.empty:
                    continue
                    
                try:
                    # Charger le sous-mod√®le
                    timeframe_path = self.store.model_path(coin_id, horizon_minutes).replace(f"__{horizon_minutes}m.pkl", f"__{timeframe}_{horizon_minutes}m.pkl")
                    
                    print(f"      üîç Recherche sous-mod√®le: {timeframe_path}")
                    if not os.path.exists(timeframe_path):
                        print(f"      ‚ùå Sous-mod√®le {timeframe} introuvable: {timeframe_path}")
                        continue
                    
                    print(f"      üìÇ Chargement sous-mod√®le {timeframe}...")
                    import pickle
                    with open(timeframe_path, "rb") as f:
                        sub_model = pickle.load(f)
                    
                    print(f"      üîß G√©n√©ration features...")
                    # G√©n√©rer features et targets
                    X, y = self.fb.build_from_five_min(df, coin_id, horizon_minutes)
                    if X is None or y is None or X.empty or y.empty:
                        print(f"      ‚ö†Ô∏è Pas de features pour {timeframe}")
                        continue
                    
                    # CORRECTION: Filtrer les NaN dans y pour les pr√©dictions
                    valid_mask = ~y.isna()
                    X_valid = X[valid_mask]
                    y_valid = y[valid_mask]
                    
                    if len(y_valid) == 0:
                        print(f"      ‚ö†Ô∏è Pas de targets valides pour {timeframe}")
                        continue
                    
                    print(f"      üéØ Pr√©dictions {timeframe} sur {len(X_valid)} √©chantillons...")
                    # Pr√©dictions du sous-mod√®le
                    predictions = sub_model.predict(X_valid.values)
                    
                    # Stocker les pr√©dictions et donn√©es
                    sub_predictions[timeframe] = predictions
                    all_features[timeframe] = X_valid
                    all_targets[timeframe] = y_valid
                    
                    print(f"      ‚úÖ {timeframe}: {len(predictions)} pr√©dictions OK")
                    
                except Exception as e:
                    print(f"      ‚ùå ERREUR sous-mod√®le {timeframe}: {e}")
                    import traceback
                    print(f"      üìç D√©tails: {traceback.format_exc()}")
                    continue
            
            if len(sub_predictions) < 2:
                print(f"      ‚ùå Pas assez de sous-mod√®les: {len(sub_predictions)} < 2")
                return {"status": "INSUFFICIENT_MODELS", "models": len(sub_predictions)}
            
            # Phase 2: Construire les features du mod√®le ma√Ætre de mani√®re align√©e
            timeframes = list(sub_predictions.keys())
            min_samples = min(len(sub_predictions[tf]) for tf in timeframes)
            
            print(f"      üìä Alignement sur {min_samples} √©chantillons")
            print(f"      üîç Debug: Sous-mod√®les utilis√©s = {timeframes}")
            
            # Construire features ma√Ætre: [features_originales + pr√©dictions_sous_mod√®les]
            base_timeframe = timeframes[0]  # Utiliser le premier timeframe comme r√©f√©rence
            base_features = all_features[base_timeframe].iloc[:min_samples].values
            base_targets = all_targets[base_timeframe].iloc[:min_samples].values
            
            # Ajouter les pr√©dictions de tous les sous-mod√®les comme features
            prediction_features = []
            for tf in timeframes:
                pred_column = sub_predictions[tf][:min_samples].reshape(-1, 1)
                prediction_features.append(pred_column)
            
            # Combiner features originales + toutes les pr√©dictions
            if prediction_features:
                all_predictions = np.column_stack(prediction_features)
                master_features = np.column_stack([base_features, all_predictions])
            else:
                master_features = base_features
            
            master_targets = base_targets
            
            print(f"      üìä Donn√©es ma√Ætre: {master_features.shape}")
            print(f"      üîç Debug: Features shape = {master_features.shape}")
            print(f"      üîç Debug: Targets shape = {master_targets.shape}")
            
            if len(master_features) < 10:
                print(f"      ‚ùå Pas assez de donn√©es ma√Ætre: {len(master_features)} < 10")
                return {"status": "INSUFFICIENT_DATA", "samples": len(master_features)}
            
            print(f"      üß† Entra√Ænement RandomForest...")
            # Utiliser RandomForest pour le mod√®le ma√Ætre
            master_model = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42, n_jobs=1)
            master_model.fit(master_features, master_targets)
            
            # √âvaluer
            mae_score = mean_absolute_error(master_targets, master_model.predict(master_features))
            
            # Sauvegarder mod√®le ma√Ætre
            master_path = self.store.model_path(coin_id, horizon_minutes).replace(f"__{horizon_minutes}m.pkl", f"__master_{horizon_minutes}m.pkl")
            
            meta = {
                "algo": "master_random_forest",
                "horizon_minutes": horizon_minutes,
                "mae_score": float(mae_score),
                "training_samples": len(master_features),
                "sub_models": list(sub_predictions.keys()),
                "created_at": datetime.now(timezone.utc).isoformat()
            }
            
            import pickle
            with open(master_path, "wb") as f:
                pickle.dump(master_model, f)
            
            # Sauvegarder m√©tadonn√©es
            meta_path = master_path.replace(".pkl", "_meta.json")
            with open(meta_path, "w", encoding="utf-8") as f:
                json.dump(meta, f, indent=2)
            
            print(f"      ‚úÖ Mod√®le ma√Ætre: MAE={mae_score:.4f}, samples={len(master_features)}")
            
            return {
                "status": "OK",
                "path": master_path,
                "mae": float(mae_score),
                "samples": len(master_features)
            }
            
        except Exception as e:
            print(f"      ‚ùå ERREUR mod√®le ma√Ætre: {e}")
            import traceback
            print(f"      üìç D√©tails: {traceback.format_exc()}")
            return {"status": "ERROR", "error": str(e)}
    
    def train_full_pipeline(self, coin_id: str, daily_df: pd.DataFrame, hourly_df: pd.DataFrame,
                           five_min_df: pd.DataFrame, horizon_minutes: int = 10, 
                           split_ratio: float = 0.7) -> Dict[str, Any]:
        """Entra√Ænement complet: sous-mod√®les + mod√®le ma√Ætre."""
        results = {"sub_models": {}, "master_model": {}, "errors": []}
        
        try:
            # Entra√Æner les sous-mod√®les
            sub_results = self.train_sub_models(
                five_min_df, coin_id, horizon_minutes
            )
            results["sub_models"] = sub_results["sub_models"]
            results["errors"].extend(sub_results["errors"])
            
            # Diviser les donn√©es pour test du mod√®le ma√Ætre
            daily_split = self._split_data(daily_df, split_ratio)
            hourly_split = self._split_data(hourly_df, split_ratio) 
            five_min_split = self._split_data(five_min_df, split_ratio)
            
            test_data = {
                "daily": daily_split.get("test", pd.DataFrame()),
                "hourly": hourly_split.get("test", pd.DataFrame()),
                "5min": five_min_split.get("test", pd.DataFrame())
            }
            
            master_result = self.train_master_model(coin_id, test_data, horizon_minutes)
            results["master_model"] = master_result
            
            return results
            
        except Exception as e:
            results["errors"].append(f"Erreur pipeline complet: {e}")
            return results
    
    def _split_data(self, df: pd.DataFrame, split_ratio: float) -> Dict[str, pd.DataFrame]:
        """Division train/test des donn√©es."""
        if df.empty:
            return {"train": pd.DataFrame(), "test": pd.DataFrame()}
        
        split_idx = int(len(df) * split_ratio)
        return {
            "train": df.iloc[:split_idx].copy(),
            "test": df.iloc[split_idx:].copy()
        }
