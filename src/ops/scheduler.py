"""
Scheduler â€” Orchestration des collecteurs et maintenance

CaractÃ©ristiques:
- Planifie lâ€™exÃ©cution pÃ©riodique des collecteurs (price, markets, chart, tickers, fx) selon settings.json
- ThreadPool minimal, timers rÃ©currents, arrÃªt gracieux via Event
- Maintenance: rÃ©tention/compaction occasionnelles via ParquetWriter

Note: MVP sans APScheduler; simple, lisible et suffisant pour lâ€™usage local.
"""

from __future__ import annotations

import os
import json
import threading
import time
from datetime import datetime, timezone
from typing import Any, Dict, List, Optional, Callable

import pandas as pd

from collectors.price_collector import PriceCollector
from collectors.markets_collector import MarketsCollector
from collectors.chart_collector import ChartCollector
from collectors.tickers_collector import TickersCollector
from collectors.fx_collector import FxCollector
from collectors.ohlc_collector import OhlcCollector
from collectors.range_collector import RangeCollector
from collectors.historical_collector import HistoricalCollector
from storage.parquet_writer import ParquetWriter
from prediction.evaluation import EvaluationJob
from ops.anti_sleep_win import AntiSleepGuard
from prediction.trainer import Trainer
from prediction.prediction_tracker import PredictionTracker
from ops.api_usage import api_snapshot


ROOT = os.path.dirname(os.path.dirname(__file__))
CONFIG_DIR = os.path.join(ROOT, "config")


def _load_json(path: str) -> Dict[str, Any]:
	with open(path, "r", encoding="utf-8") as f:
		return json.load(f)


def _settings() -> Dict[str, Any]:
	return _load_json(os.path.join(CONFIG_DIR, "settings.json"))


class _PeriodicTask:
	def __init__(self, name: str, interval_sec: int, fn: Callable[[], None], initial_delay_sec: int = 0) -> None:
		self.name = name
		self.interval_sec = max(1, int(interval_sec))
		self.initial_delay_sec = max(0, int(initial_delay_sec))
		self.fn = fn
		self._stop = threading.Event()
		self._thread = threading.Thread(target=self._run, name=f"Task-{name}", daemon=True)

	def start(self) -> None:
		self._thread.start()

	def stop(self) -> None:
		self._stop.set()
		self._thread.join(timeout=5)

	def _run(self) -> None:
		# DÃ©lai initial avant la premiÃ¨re exÃ©cution
		next_run = time.time() + self.initial_delay_sec
		while not self._stop.is_set():
			now = time.time()
			if now >= next_run:
				try:
					self.fn()
				except RuntimeError as e:
					# Rate limiter ou API throttling - attendre un peu plus longtemps
					print(f"Task {self.name} throttled: {e}, retrying in {self.interval_sec + 30}s")
					next_run = now + self.interval_sec + 30  # Attendre 30s de plus
					continue
				except Exception as e:
					# Autres erreurs - log et continuer
					print(f"Task {self.name} error: {e}")
				next_run = now + self.interval_sec
			time.sleep(0.2)


class Scheduler:
	def __init__(self) -> None:
		self.s = _settings()
		self.writer = ParquetWriter()
		# Collecteurs
		self.price = PriceCollector()
		self.markets = MarketsCollector(writer=self.writer)
		self.chart = ChartCollector(writer=self.writer)
		self.tickers = TickersCollector(writer=self.writer)
		self.fx = FxCollector(writer=self.writer)
		self.ohlc = OhlcCollector(writer=self.writer)
		self.range = RangeCollector(writer=self.writer)
		self.historical = HistoricalCollector(writer=self.writer)
		self.eval = EvaluationJob()
		self.trainer = Trainer(verbose=False)  # Mode silencieux pour les updates pÃ©riodiques
		self.prediction_tracker = PredictionTracker()  # Gestionnaire des prÃ©dictions CLI
		# Anti-sommeil (Windows) si activÃ©
		feat = self.s.get("features", {})
		self._antisleep = AntiSleepGuard(enabled=bool(feat.get("anti_sleep_windows", False)))
		# TÃ¢ches pÃ©riodiques normales
		cad = self.s.get("cadences", {}).get("collectors", {})
		self.tasks = [
			_PeriodicTask("price", cad.get("simple_price_pull_sec", 10), self._do_price),
			_PeriodicTask("markets", cad.get("coins_markets_pull_sec", 60), self._do_markets),
			_PeriodicTask("chart", cad.get("market_chart_pull_sec", 300), self._do_chart),
			_PeriodicTask("tickers", cad.get("tickers_pull_sec", 600), self._do_tickers),
			_PeriodicTask("fx", cad.get("fx_pull_sec", 3600), self._do_fx),
			_PeriodicTask("maintenance", 1800, self._maintenance),  # 30 min
			_PeriodicTask("evaluation", cad.get("evaluation_pull_sec", 120), self._evaluation),
		]
		
		# TÃ¢che de vÃ©rification des prÃ©dictions CLI (toutes les 2 minutes)
		self.tasks.append(_PeriodicTask("prediction_verification", 120, self._do_prediction_verification, initial_delay_sec=30))
		
		# TÃ¢che d'entraÃ®nement pÃ©riodique (mini retrain 10 min par dÃ©faut)
		try:
			train_cad = self.s.get("cadences", {}).get("training", {})
			mini_min = int(train_cad.get("mini_retrain_min", 10))
			# DÃ©lai initial de 2 minutes pour laisser le bot se stabiliser
			self.tasks.append(_PeriodicTask("training", max(60, mini_min * 60), self._do_training, initial_delay_sec=120))
		except Exception:
			pass
		
		# TÃ¢che de collecte historique (une seule fois au dÃ©marrage si pas dÃ©jÃ  fait)
		self._historical_collected = False
		self.tasks.append(_PeriodicTask("historical_once", 300, self._do_historical_once))  # VÃ©rifier toutes les 5 min si pas fait
		
		# TÃ¢ches de maintenance historique quotidienne
		self.tasks.append(_PeriodicTask("ohlc_daily", 21600, self._do_ohlc_daily))  # 6h
		self.tasks.append(_PeriodicTask("range_validation", 43200, self._do_range_validation))  # 12h
		
		# TÃ¢che de nettoyage des modÃ¨les (quotidienne)
		self.tasks.append(_PeriodicTask("model_cleanup", 86400, self._do_model_cleanup, initial_delay_sec=3600))  # 24h, dÃ©lai 1h

		# Charger la liste de coins depuis la config
		try:
			coins_cfg = _load_json(os.path.join(CONFIG_DIR, "coins.json"))
			self._coins = [c.get("id") for c in coins_cfg.get("coins", []) if c.get("enabled", True)]
		except Exception:
			self._coins = []

	# --- Actions ---
	def _do_price(self) -> None:
		try:
			self.price.get_prices()
		except Exception:
			pass

	def _do_markets(self) -> None:
		try:
			self.markets.collect()
		except Exception:
			pass

	def _do_chart(self) -> None:
		try:
			self.chart.collect()
		except Exception:
			pass

	def _do_tickers(self) -> None:
		try:
			self.tickers.collect()
		except Exception:
			pass

	def _do_fx(self) -> None:
		try:
			self.fx.collect()
		except Exception:
			pass

	def _do_historical_once(self) -> None:
		"""Collecte historique massive une seule fois au dÃ©marrage."""
		if self._historical_collected:
			return
		
		# VÃ‰RIFIER SI ON A DÃ‰JÃ€ DES DONNÃ‰ES !
		from storage.parquet_writer import ParquetWriter
		writer = ParquetWriter()
		data_path = writer.settings["paths"]["data_parquet"]
		
		# Checker si des donnÃ©es existent dÃ©jÃ 
		datasets = ["five_min", "hourly", "daily"]
		has_data = False
		for dataset in datasets:
			dataset_path = os.path.join(data_path, dataset)
			if os.path.exists(dataset_path) and os.listdir(dataset_path):
				has_data = True
				break
		
		if has_data:
			print("ðŸ“Š DONNÃ‰ES HISTORIQUES DÃ‰JÃ€ PRÃ‰SENTES - Skip collecte automatique")
			self._historical_collected = True  # Marquer comme fait
			return
		
		try:
			print("ðŸš€ DÃ©marrage collecte historique massive...")
			results = self.historical.collect_all_historical()
			
			# Marquer comme fait
			self._historical_collected = True
			
			# Log rÃ©sultats
			summary = results.get("summary", {})
			total_points = summary.get("total_points_collected", 0)
			print(f"âœ… Collecte historique terminÃ©e: {total_points:,} points collectÃ©s")
			
		except Exception as e:
			print(f"âŒ Erreur collecte historique: {e}")
			# Ne pas marquer comme fait pour rÃ©essayer au prochain dÃ©marrage

	def _do_ohlc_daily(self) -> None:
		"""Collecte OHLC quotidienne pour maintenir l'historique."""
		try:
			print(f"ðŸ“Š Collecte OHLC quotidienne...")
			# Utiliser la liste des coins configurÃ©s
			coin_ids = ["bitcoin", "ethereum", "solana", "binancecoin", "cardano"]
			self.ohlc.collect_daily_batch(coin_ids, days=1)
			print(f"âœ… OHLC quotidien terminÃ©")
		except Exception as e:
			print(f"âŒ Erreur OHLC quotidien: {e}")

	def _do_range_validation(self) -> None:
		"""Collecte de ranges pour validation croisÃ©e."""
		try:
			print(f"ðŸ“ˆ Collecte ranges validation...")
			# Utiliser range des derniÃ¨res 24h
			import time
			now_ms = int(time.time() * 1000)
			frm_ms = now_ms - (24 * 3600 * 1000)  # 24h ago
			coin_ids = ["bitcoin", "ethereum", "solana"]
			self.range.collect_validation_ranges(coin_ids, frm_ms, now_ms)
			print(f"âœ… Collecte ranges terminÃ©e")
		except Exception as e:
			print(f"âŒ Erreur collecte ranges: {e}")

	def _maintenance(self) -> None:
		try:
			# RÃ©tention optimisÃ©e selon nouvelle stratÃ©gie 300 GB
			self.writer.enforce_retention("five_min", timeframe="five_min")  # 30 jours
			self.writer.enforce_retention("hourly", timeframe="hourly")      # 2 ans  
			self.writer.enforce_retention("daily", timeframe="daily")        # 100 ans (lÃ©ger)
			self.writer.enforce_retention("markets", timeframe="markets")    # Config
			self.writer.enforce_retention("tickers_spread", timeframe="tickers_spread")
			self.writer.enforce_retention("fx", timeframe="hourly")
			self.writer.enforce_retention("predictions", timeframe="predictions")
			self.writer.enforce_retention("eval_results", timeframe="eval_results")
			
			# Compaction optimisÃ©e
			today = datetime.now(timezone.utc).strftime("%Y-%m-%d")
			for ds in ["five_min", "hourly", "daily", "markets", "tickers_spread", "fx", "predictions", "eval_results"]:
				self.writer.compact_partition(ds, today)
				
			# Rotation intelligente des donnÃ©es anciennes (si espace > 250 GB)
			self._auto_data_rotation()
			
		except Exception:
			pass

	def _auto_data_rotation(self) -> None:
		"""Rotation automatique si approche de la limite 300 GB."""
		try:
			import shutil
			
			# VÃ©rifier espace utilisÃ©
			data_path = self.s["paths"]["data_parquet"]
			if os.path.exists(data_path):
				total_size = sum(os.path.getsize(os.path.join(dirpath, filename))
								for dirpath, dirnames, filenames in os.walk(data_path)
								for filename in filenames)
				size_gb = total_size / (1024**3)
				
				# Si > 250 GB, commencer rotation (marge sÃ©curitÃ©)
				if size_gb > 250:
					print(f"âš ï¸  Rotation donnÃ©es: {size_gb:.1f} GB utilisÃ©s")
					# Supprimer les plus anciens five_min (garder 7 derniers jours)
					self.writer.enforce_retention("five_min", days=7)
					# RÃ©duire hourly Ã  1 an
					self.writer.enforce_retention("hourly", days=365)
		except Exception:
			pass

	def _evaluation(self) -> None:
		try:
			self.eval.evaluate_pending()
		except Exception:
			pass

	def _read_recent_five_min(self) -> Optional[pd.DataFrame]:
		"""Lecture robuste du dataset five_min, retour DataFrame ou None."""
		try:
			root = self.s["paths"]["data_parquet"]
			path = os.path.join(root, "five_min")
			if not os.path.isdir(path):
				return None
			try:
				return pd.read_parquet(path)
			except Exception:
				frames: list[pd.DataFrame] = []
				for r, _, files in os.walk(path):
					for f in files:
						if f.endswith(".parquet"):
							fp = os.path.join(r, f)
							try:
								frames.append(pd.read_parquet(fp))
							except Exception:
								pass
				if frames:
					return pd.concat(frames, ignore_index=True)
				return None
		except Exception:
			return None

	def _do_training(self) -> None:
		"""Mini retrain: entraÃ®ne un modÃ¨le +10 min pour chaque coin actif sur les derniÃ¨res donnÃ©es."""
		try:
			df = self._read_recent_five_min()
			if df is None or df.empty:
				return
			for cid in self._coins or []:
				try:
					# Garder un sous-ensemble rÃ©cent par coin (par sÃ©curitÃ©)
					sub = df[df["coin_id"] == cid].sort_values("ts_utc_ms").tail(2000)
					if sub.empty:
						continue
					self.trainer.train(sub, cid, horizon_minutes=10)
				except Exception:
					# Continuer avec d'autres coins mÃªme si un Ã©choue
					pass
		except Exception:
			pass

	def _do_prediction_verification(self) -> None:
		"""VÃ©rifie les prÃ©dictions CLI en attente et met Ã  jour les modÃ¨les si nÃ©cessaire."""
		try:
			pending_predictions = self.prediction_tracker.check_pending_predictions()
			
			for prediction in pending_predictions:
				try:
					self.prediction_tracker.verify_prediction(prediction)
				except Exception:
					# Continuer avec d'autres prÃ©dictions mÃªme si une Ã©choue
					pass
					
		except Exception:
			pass

	def _do_model_cleanup(self) -> None:
		"""Nettoyage automatique des anciens modÃ¨les."""
		try:
			from prediction.model_store import ModelStore
			store = ModelStore()
			
			# ParamÃ¨tres de nettoyage (configurables)
			max_age_days = 7  # Supprimer modÃ¨les > 7 jours
			max_models_per_coin_horizon = 3  # Garder 3 meilleurs par coin/horizon
			
			print(f"ðŸ§¹ Nettoyage automatique des modÃ¨les...")
			report = store.cleanup_old_models(
				max_age_days=max_age_days,
				max_models_per_coin_horizon=max_models_per_coin_horizon
			)
			
			stats = report.get("stats", {})
			deleted = stats.get("total_deleted", 0)
			kept = stats.get("total_kept", 0)
			
			print(f"   ðŸ—‘ï¸ SupprimÃ©s: {deleted} modÃ¨les")
			print(f"   âœ… ConservÃ©s: {kept} modÃ¨les")
			
			if report.get("errors"):
				print(f"   âš ï¸ Erreurs: {len(report['errors'])}")
			
		except Exception as e:
			print(f"âš ï¸ Erreur nettoyage modÃ¨les: {e}")

	# --- Cycle de vie ---
	def start(self) -> None:
		# Activer anti-sommeil best-effort
		try:
			self._antisleep.start()
		except Exception:
			pass
		for t in self.tasks:
			t.start()

	def stop(self) -> None:
		for t in self.tasks:
			t.stop()
		try:
			self._antisleep.stop()
		except Exception:
			pass


def main() -> None:
	sch = Scheduler()
	sch.start()
	try:
		while True:
			time.sleep(1)
	except KeyboardInterrupt:
		pass
	finally:
		sch.stop()


if __name__ == "__main__":
	main()

